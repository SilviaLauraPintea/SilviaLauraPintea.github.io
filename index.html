<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Home | Silvia-Laura Pintea</title>
	<meta name="keywords" content="Silvia-Laura Pintea" />
	<link rel="stylesheet" href="style.css" type="text/css"/>
</head>

<body>
	<div class="header"><h1>Silvia-Laura Pintea</h1></div>
	<div class="hr"></div>
	<div class="menu">
		<a class="selected" href="/">HOME</a>
		<a href="publications.html">PUBLICATIONS</a>
		<a href="guiding.html">GUIDING & TEACHING</a>
	</div>
	<div class="hr"></div>
	
	<div class="content">	
		<div style="float:left;padding:5px 75px 25px 0px; width:270px">
			<img src="silvia.png?w=200&#038;h=200" alt="silvia" width="200" height="200" />
			<p>dr. Silvia-Laura Pintea</p>
		    <p>Computer Vision Research</p>
		    </br>
		    </br>
            <p><span class="bold">Google scholar:</span><a href="https://scholar.google.nl/citations?user=shTkx9EAAAAJ&hl=en">Link</a></p>
			<p><span class="bold">Email:</span><a href="mailto:silvia.laura.pintea@gmail.com">Silvia<i>[dot]</i>Laura<i>[dot]</i>Pintea<i>[at]</i>gmail<i>[dot]</i>com</a></p>
			<p><span class="bold">Github:</span><a style="font-size:13px" href="https://github.com/SilviaLauraPintea">https://github.com/SilviaLauraPintea</a>
			<p><span class="bold">Curriculum Vitae:</span> <a title="CV" style="font-size:13px" href="cv/cv.pdf">CV</a></p>
		</div>

        </br>
        I am a Computer Vision researcher that loves puzzling with visual learning problems.</br>
        Everything visual: from colors, edges and corners in images, to time and motion in videos, catches my interest.</br> 
        </br>
        I would love to know how to solve real world problems and make this world kinder, better.
        But, for now all I can do is play with pixels. 

		<div class="overflow" style="float:left; padding:15px 5px 10px 80px; width:400px">
            <h2 style="text-align:left;"> 2025 news: </h2>
            <ul>
                <li><b>Award:</b> Outstanding reviewer for CVPR-2025</li>
                <li><b>New position:</b> At Tilburg University in the <a href="https://www.tilburguniversity.edu/about/schools/tshd/departments/dca/lab">"Deep learning for perception" lab</a></li>
                <li><b>Organization:</b> I am reviewer for BMVC-2025</li>
                <li><b>Farewell LKEB talk</b>:<a href="talks/the_ideal_lab.pdf">"The ideal lab"</a></li>
                <li><b>Organization:</b> I am reviewer for ICCV-2025</li>
                <li><b>Organization:</b> I am reviewer for CVPR-2025</li>
                <li><b>Conference paper:</b><a href="https://arxiv.org/abs/2503.03367">(ISBI 2025)</a><i> Top-K Maximum Intensity Projection Priors for 3D Liver Vessel Segmentation</i></li>
                <li><b>Organization:</b> I am reviewer for WACV-2025</li>
            </ul>
            <h2 style="text-align:left;"> 2024 news: </h2>
            <ul>
                <li><b>Talk</b> at the Radiology Research Summit (LUMC): <a href="motion.pdf">"Motion representations for visual analysis"</a></li>
                <li><b>Organization:</b> I am reviewer for BMVC-2024</li>
                <li><b>PhD committee:</b> For the PhD defense of Dr. Xin Liu</li>
                <li><b>Organization:</b> I am reviewer for ECCV-2024</li>
                <li><b>Organization:</b> I am reviewer for CVPR-2024</li>
                <li><b>Organization:</b> I am reviewer for WACV-2024</li>
                <li><b>Organization:</b> Organizing an ML/DL reading group at LKEB-LUMC</li>
            </ul>
            <h2 style="text-align:left;"> 2023 news: </h2>
            <ul>
                <li><b>Accepted paper:</b><a href="https://arxiv.org/abs/2308.10603">(ICCV-2023)</a><i>"A step towards understanding why classification helps regression"</i></li>
                <li><b>Accepted paper:</b><a href="https://arxiv.org/abs/2308.04770">(ICCV-2023)</a><i>"Objects do not disappear: Video object detection by single-frame object location anticipation"</i></li> 
                <li><b>Accepted paper:</b><a href="https://arxiv.org/abs/2308.05533">(ICCVw-2023)</a><i>"Is there progress in activity progress prediction?"</i></li> 
                <li><b>Organization:</b> I am reviewer for ICCV-2023</li>
                <li><b>Organization:</b> I am reviewer for CVPR-2023</li>
                <li><b>Organization:</b> Organizing a "Diffusion Models" reading group at LKEB-LUMC</li>
            </ul>
            <h2 style="text-align:left;"> 2022 news: </h2>
            <ul>
                <li><b>PhD committee:</b> For the PhD defense of Dr. Yancong Lin</li>
                <li><b>Accepted paper:</b><a href="https://arxiv.org/abs/2112.03406">(AAAI-2022)</a><i>"Equal Bits: Enforcing Equally Distributed Binary Network Weights"</i></li> 
                <li><b>Accepted paper:</b>i<a href="https://arxiv.org/abs/2112.12579">(BMVC-2022)</a><i>"NeRD++: Improved 3D-mirror symmetry learning from a single image"</i></li> 
                <li><b>Accepted paper:</b><a href="https://arxiv.org/abs/2203.08586">(CVPR-2022)</a><i>"Deep vanishing point detection: Geometric priors make dataset variations vanish"</i></li> 
                <li><b>Award:</b> Outstanding reviewer for BMVC-2022</li>
                <li><b>Award:</b> Outstanding reviewer for ECCV-2022</li>
                <li><b>Talk</b> at the Startup Village Amsterdam </li>
                <li><b>Award:</b> Outstanding reviewer for CVPR-2022</li>
                <li><b>Organization:</b> I am reviewer for WACV-2022</li>
                <li><b>New position:</b> At LUMC in the <a href="https://lkeb.github.io/people.html">"Division of Image processing (LKEB)"</a></li>
            </ul>
            <h2 style="text-align:left;"> 2021 news: </h2>
            <ul>
                <li><b>Accepted paper:</b> (COMG-2021) <i>"Seismic inversion with deep learning: A proposal for litho-type"</i></li> 
                <li><b>Accepted paper:</b><a href="https://arxiv.org/abs/2111.06660">(BMVC-2021)</a><i>"Frequency learning for structured CNN filters with Gaussian fractional derivatives"</i></li> 
                <li><b>Accepted paper:</b><a href="https://arxiv.org/abs/2106.03412">(TIP-2021)</a><i>"Resolution learning in deep convolutional networks using scale-space theory"</i></li> 
                <li><b>Accepted paper:</b><a href="https://arxiv.org/abs/2402.01557">(ICML-2021)</a><i>"Deep continuous networks"</i></li> 
                <li><b>Accepted paper:</b><a href="https://arxiv.org/abs/2106.05094">(ICIP-2021)</a><i>"Semi-supervised lane detection with Deep Hough Transform"</i></li> 
                <li><b>Accepted paper:</b><a href="https://arxiv.org/abs/2103.15395">(CVPR-2021)</a><i>"No frame left behind: Full Video Action Recognition"</i></li> 
                <li><b>Award:</b> Outstanding reviewer for BMVC-2021</li>
                <li><b>Award:</b> Outstanding reviewer for ICCV-2021</li>
                <li><b>Award:</b> Outstanding reviewer for CVPR-2021</li>
            </ul>
            <h2 style="text-align:left;"> 2020 news: </h2>
            <ul>
                <li><b>Accepted paper:</b><a href="https://arxiv.org/abs/2007.09493">(ECCV-2020)</a><i>"Deep Hough-Transform Line Priors"</i></li> 
                <li><b>Accepted paper:</b><a href="https://arxiv.org/abs/2004.07629">(CVPRw-2020)</a><i>"Top-Down Networks: A coarse-to-fine reimagination of CNN"</i></li> 
                <li><b>Organization:</b> I am reviewer for BMVC-2020</li>
                <li><b>Organization:</b> I am reviewer for ECCV-2020</li>
                <li><b>Organization:</b> I am reviewer for CVPR-2020</li>
            </ul>
            <h2 style="text-align:left;"> 2019 news: </h2>
            <ul>
                <li><b>Talk</b> at the AIRLab (Delft) </li>
                <li><b>Organization:</b> I am reviewer for ICCV-2019</li>
                <li><b>Talk</b> at the Leiden University ("Deep Learning Seminar")</li>
                <li><b>Organization:</b> I am reviewer for CVPR-2019</li>
            </ul>
            <h2 style="text-align:left;"> 2018 news: </h2>
            <ul>
                <li><b>Accepted paper:</b> (TIP-2018) <i>"Divide and Count: Generic Object Counting by Image Divisions"</i></li> 
                <li><b>Accepted paper:</b><a href="https://arxiv.org/abs/1809.03258">(ECCVw-2018)</a><i>"Using phase instead of optical flow for action recognition"</i></li>     
                <li><b>Award:</b> Best paper at <a href="https://arxiv.org/abs/1809.03218">(ECCVw-2018)</a><i>"Hand-tremor Frequency Estimation in Videos"</i></li> 
                <li><b>Accepted paper:</b><a href="https://arxiv.org/abs/1805.07170">(ICIP-2018)</a><i>"Recurrent knowledge distillation"</i></li>     
                <li><b>Accepted paper:</b> (PRLetters-2018) <i>"Asymmetric kernels in Gaussian Process for learning target variance"</i></li> 
                <li><b>Organization:</b> I am reviewer for ECCV-2018</li>
                <li><b>Organization:</b> I am reviewer for CVPR-2018</li>
            </ul>
            <h2 style="text-align:left;"> 2017 news: </h2>
            <ul>
                <li><b>Accepted paper:</b><a href="https://arxiv.org/abs/1704.04186">(CVPR-2017)</a><i>Video Acceleration Magnification</i>.</li> 
                <li><b>PhD thesis</b>: <a href="http://dare.uva.nl/search?identifier=90ad88f5-c16e-4450-86f2-23faa250fcab">"Continuous Learning in Computer Vision"</a></li> 
                <li><b>Organization:</b> I am reviewer for ICCV-2017</li>
                <li><b>Organization:</b> I am reviewer for CVPR-2017</li>
            </ul>
            <h2 style="text-align:left;"> 2016 news: </h2>
            <ul>
                <li><b>Accepted paper:</b> (ICIP-2016) <i>"Featureless: Bypassing Feature Extraction In Action Categorization"</i></li>
                <li><b>Organization:</b> I am reviewer for ECCV-2016</li>
                <li><b>Organization:</b> I am reviewer for CVPR-2016</li>
                <li><b>New position:</b> At TUDelft in the <a href="https://www.tudelft.nl/ewi/over-de-faculteit/afdelingen/intelligent-systems/pattern-recognition-bioinformatics/computer-vision-lab">Computer Vision Lab</a></li>
            </ul>
		</div>
		<div style="clear:both;"></div>

	</div>
</body>
</html>

